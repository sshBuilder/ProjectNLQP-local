[
    {
        "url": "https://www.ibm.com/think/topics/machine-learning",
        "title": "What Is Machine Learning (ML)? | IBM",
        "content": [
            "Machine learning (ML) is a branch of artificial intelligence (AI) focused on enabling computers and machines to imitate the way that humans learn, to perform tasks autonomously, and to improve their performance and accuracy through experience and exposure to more data.",
            "UC Berkeleybreaks out the learning system of a machine learning algorithm into three main parts.",
            "Discover expertly curated insights and news on AI, cloud and more in the weekly Think Newsletter.",
            "Since deep learning and machine learning tend to be used interchangeably, it’s worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks.",
            "The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn’t necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture1.",
            "Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn.",
            "Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The “deep” in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers—which would be inclusive of the input and the output—can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network.",
            "Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition.",
            "See the blog post “AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What’s the Difference?” for a closer look at how the different concepts relate.",
            "Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights.",
            "Machine learning models fall into three primary categories.",
            "Supervised learning, also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, naïve bayes, linear regression, logistic regression, random forest, and support vector machine (SVM).",
            "Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method’s ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It’s also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods.",
            "Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it’s too costly to label enough data.",
            "For a deep dive into the differences between these approaches, check out \"Supervised vs. Unsupervised Learning: What's the Difference?\"",
            "Reinforcement machine learning is a machine learning model that is similar to supervised learning, but the algorithm isn’t trained using sample data. This model learns as it goes by using trial and error. A sequence of successful outcomes will be reinforced to develop the best recommendation or policy for a given problem.",
            "The IBM Watson® system that won the Jeopardy! challenge in 2011 is a good example. The system used reinforcement learning to learn when to attempt an answer (or question, as it were), which square to select on the board, and how much to wager—especially on daily doubles.",
            "A number of machine learning algorithms are commonly used. These include:",
            "Neural networks simulate the way the human brain works, with a huge number of linked processing nodes. Neural networks are good at recognizing patterns and play an important role in applications including natural language translation, image recognition, speech recognition, and image creation.",
            "This algorithm is used to predict numerical values, based on a linear relationship between different values. For example, the technique could be used to predict house prices based on historical data for the area.",
            "This supervised learning algorithm makes predictions for categorical response variables, such as “yes/no” answers to questions. It can be used for applications such as classifying spam and quality control on a production line.",
            "Using unsupervised learning, clustering algorithms can identify patterns in data so that it can be grouped. Computers can help data scientists by identifying differences between data items that humans have overlooked.",
            "Decision trees can be used for both predicting numerical values (regression) and classifying data into categories. Decision trees use a branching sequence of linked decisions that can be represented with a tree diagram. One of the advantages of decision trees is that they are easy to validate and audit, unlike the black box of the neural network.",
            "In a random forest, the machine learning algorithm predicts a value or category by combining the results from a number of decision trees.",
            "Depending on your budget, need for speed and precision required, each algorithm type—supervised, unsupervised, semi-supervised, or reinforcement—has its own advantages and disadvantages. For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories. Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram. A prime advantage of decision trees is that they are easier to validate and audit than a neural network. The bad news is that they can be more unstable than other decision predictors.\n\r\nOverall, there are many advantages to machine learning that businesses can leverage for new efficiencies. These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all. And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms—which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person.\n\r\nOn the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output.",
            "Here are just a few examples of machine learning you might encounter every day:",
            "Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search—e.g. Siri—or improve accessibility for texting.",
            "Customer service:Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites; messaging bots, using Slack and Facebook Messenger; and tasks usually done by virtual assistants and voice assistants.",
            "Computer vision: This AI technology enables computers to derive meaningful information from digital images, videos, and other visual inputs, and then take the appropriate action. Powered by convolutional neural networks, computer vision has applications in photo tagging on social media, radiology imaging in healthcare, and self-driving cars in the automotive industry.",
            "Recommendation engines: Using past consumption behavior data, AI algorithms can help to discover data trends that can be used to develop more effective cross-selling strategies. Recommendation engines are used by online retailers to make relevant product recommendations to customers during the checkout process.\n\nRobotic process automation (RPA): Also known as software robotics, RPA uses intelligent automation technologies to perform repetitive manual tasks.",
            "Automated stock trading: Designed to optimize stock portfolios, AI-driven high-frequency trading platforms make thousands or even millions of trades per day without human intervention.",
            "Fraud detection: Banks and other financial institutions can use machine learning to spot suspicious transactions. Supervised learning can train a model using information about known fraudulent transactions. Anomaly detection can identify transactions that look atypical and deserve further investigation.",
            "As machine learning technology has developed, it has certainly made our lives easier. However, implementing machine learning in businesses has also raised a number of ethical concerns about AI technologies. Some of these include:",
            "While this topic garners a lot of public attention, many researchers are not concerned with the idea of AI surpassing human intelligence in the near future. Technological singularity is also referred to as strong AI or superintelligence. Philosopher Nick Bostrum defines superintelligence as “any intellect that vastly outperforms the best human brains in practically every field, including scientific creativity, general wisdom, and social skills.” Despite the fact that superintelligence is not imminent in society, the idea of it raises some interesting questions as we consider the use of autonomous systems, like self-driving cars. It’s unrealistic to think that a driverless car would never have an accident, but who is responsible and liable under those circumstances? Should we still develop autonomous vehicles, or do we limit this technology to semi-autonomous vehicles which help people drive safely? The jury is still out on this, but these are the types of ethical debates that are occurring as new, innovative AI technology develops.",
            "While a lot of public perception of artificial intelligence centers around job losses, this concern should probably be reframed. With every disruptive, new technology, we see that the market demand for specific job roles shifts. For example, when we look at the automotive industry, many manufacturers, like GM, are shifting to focus on electric vehicle production to align with green initiatives. The energy industry isn’t going away, but the source of energy is shifting from a fuel economy to an electric one.",
            "In a similar way, artificial intelligence will shift the demand for jobs to other areas. There will need to be individuals to help manage AI systems. There will still need to be people to address more complex problems within the industries that are most likely to be affected by job demand shifts, such as customer service. The biggest challenge with artificial intelligence and its effect on the job market will be helping people to transition to new roles that are in demand.",
            "Privacy tends to be discussed in the context of data privacy, data protection, and data security. These concerns have allowed policymakers to make more strides in recent years. For example, in 2016, GDPR legislation was created to protect the personal data of people in the European Union and European Economic Area, giving individuals more control of their data. In the United States, individual states are developing policies, such as the California Consumer Privacy Act (CCPA), which was introduced in 2018 and requires businesses to inform consumers about the collection of their data. Legislation such as this has forced companies to rethink how they store and use personally identifiable information (PII). As a result, investments in security have become an increasing priority for businesses as they seek to eliminate any vulnerabilities and opportunities for surveillance, hacking, and cyberattacks.",
            "Instances of bias and discrimination across a number of machine learning systems have raised many ethical questions regarding the use of artificial intelligence. How can we safeguard against bias and discrimination when the training data itself may be generated by biased human processes? While companies typically have good intentions for their automation efforts, Reuters2 highlights some of the unforeseen consequences of incorporating AI into hiring practices. In their effort to automate and simplify a process, Amazon unintentionally discriminated against job candidates by gender for technical roles, and the company ultimately had to scrap the project. Harvard Business Review3 has raised other pointed questions about the use of AI in hiring practices, such as what data you should be able to use when evaluating a candidate for a role.",
            "Bias and discrimination aren’t limited to the human resources function either; they can be found in a number of applications from facial recognition software to social media algorithms.",
            "As businesses become more aware of the risks with AI, they’ve also become more active in this discussion around AI ethics and values. For example, IBM has sunset its general purpose facial recognition and analysis products. IBM CEO Arvind Krishna wrote: “IBM firmly opposes and will not condone uses of any technology, including facial recognition technology offered by other vendors, for mass surveillance, racial profiling, violations of basic human rights and freedoms, or any purpose which is not consistent with our values and Principles of Trust and Transparency.”",
            "Since there isn’t significant legislation to regulate AI practices, there is no real enforcement mechanism to ensure that ethical AI is practiced. The current incentives for companies to be ethical are the negative repercussions of an unethical AI system on the bottom line. To fill the gap, ethical frameworks have emerged as part of a collaboration between ethicists and researchers to govern the construction and distribution of AI models within society. However, at the moment, these only serve to guide. Some research4 shows that the combination of distributed responsibility and a lack of foresight into potential consequences aren’t conducive to preventing harm to society.",
            "Selecting a platform can be a challenging process, as the wrong system can drive up costs, or limit the use of other valuable tools or technologies. When reviewing multiple vendors to select an AI platform, there is often a tendency to think that more features = a better system. Maybe so, but reviewers should start by thinking through what the AI platform will be doing for their organization. What machine learning capabilities need to be delivered and what features are important to accomplish them? One missing feature might doom the usefulness of an entire system. Here are some features to consider.",
            "Learn how to confidently incorporate generative AI and machine learning into your business.",
            "Learn fundamental concepts and build your skills with hands-on labs, courses, guided projects, trials and more.",
            "Learn how to confidently incorporate generative AI and machine learning into your business.",
            "Want to get a better return on your AI investments? Learn how scaling gen AI in key areas drives change by helping your best minds build and deliver innovative new solutions.",
            "Learn how to select the most suitable AI foundation model for your use case.",
            "IBM® Granite™ is our family of open, performant and trusted AI models, tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options.",
            "Dive into the 3 critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI.",
            "We surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead.",
            "Train, validate, tune and deploy generative AI, foundation models and machine learning capabilities with IBM watsonx.ai, a next-generation enterprise studio for AI builders. Build AI applications in a fraction of the time with a fraction of the data.",
            "Put AI to work in your business with IBM's industry-leading AI expertise and portfolio of solutions at your side.",
            "Reinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value.",
            "Get one-stop access to capabilities that span the AI development lifecycle. Produce powerful AI solutions with user-friendly interfaces, workflows and access to industry-standard APIs and SDKs.",
            "1 Deep Learning Basics: Introduction and Overview",
            "2 Insight - Amazon scraps secret AI recruiting tool that showed bias against women, Reuters, 10 October 2018",
            "3 The Legal and Ethical Implications of Using AI in Hiring, Harvard Business Review, 25 April 2019",
            "4 The Ethics of AI Ethics, An Evaluation of Guidelines, Dr. Thilo Hagendorff"
        ]
    },
    {
        "url": "https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained",
        "title": "Machine learning, explained | MIT Sloan",
        "content": [
            "MIT Sloan is the leader in research and teaching in AI.\nDive in to discover why.",
            "Through intellectual rigor and experiential learning, this full-time, two-year MBA program develops leaders who make a difference in the world.",
            "Earn your MBA and SM in engineering with this transformative two-year program.",
            "A rigorous, hands-on program that prepares adaptive problem solvers for premier finance careers.",
            "A 12-month program focused on applying the tools of modern data science, optimization and machine learning to solve real-world business problems.",
            "Combine an international MBA with a deep dive into management science. A special opportunity for partner and affiliate schools only.",
            "A doctoral program that produces outstanding scholars who are leading in their fields of research.",
            "Bring a business perspective to your technical and quantitative expertise with a bachelor’s degree in management, business analytics, or finance.",
            "Apply now and work for two to five years. We'll save you a seat in our MBA class when you're ready to come back to campus for your degree.",
            "The 20-month program teaches the science of management to mid-career leaders who want to move from success to significance.",
            "A full-time MBA program for mid-career leaders eager to dedicate one year of discovery for a lifetime of impact.",
            "A joint program for mid-career professionals that integrates engineering and systems thinking. Earn your master’s degree in engineering and management.",
            "Non-degree programs for senior executives and high-potential managers.",
            "A non-degree, customizable program for mid-career professionals.",
            "Scope 3 emissions top supply chain sustainability challenges",
            "3 ways to improve the mortgage market",
            "14 quotes for business and management from 2024",
            "Credit: Andriy Onufriyenko / Getty Images",
            "Ideas Made to Matter",
            "Artificial Intelligence",
            "By",
            "Sara Brown",
            "Apr 21, 2021",
            "This pervasive and powerful form of artificial intelligence is changing every industry. Here’s what you need to know about the potential and limitations of machine learning and how it’s being used.",
            "Machine learning is behind chatbots and predictive text, language translation apps, the shows Netflix suggests to you, and how your social media feeds are presented. It powers autonomous vehicles and machines that can diagnose medical conditions based on images.",
            "When companies today deploy artificial intelligence programs, they are most likely using machine learning — so much so that the terms are often used interchangeably, and sometimes ambiguously. Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without explicitly being programmed.",
            "“In just the last five or 10 years, machine learning has become a critical way, arguably the most important way, most parts of AI are done,” said MIT Sloan professorThomas W. Malone, the founding director of the MIT Center for Collective Intelligence. “So that's why some people use the terms AI and machine learning almost as synonymous … most of the current advances in AI have involved machine learning.”",
            "With the growing ubiquity of machine learning, everyone in business is likely to encounter it and will need some working knowledge about this field. A 2020 Deloitte survey found that 67% of companies are using machine learning, and 97% are using or planning to use it in the next year.",
            "From manufacturing to retail and banking to bakeries, even legacy companies are using machine learning to unlock new value or boost efficiency. “Machine learning is changing, or will change, every industry, and leaders need to understand the basic principles, the potential, and the limitations,” said MIT computer science professor Aleksander Madry, director of the MIT Center for Deployable Machine Learning.",
            "While not everyone needs to know the technical details, they should understand what the technology does and what it can and cannot do, Madry added. “I don’t think anyone can afford not to be aware of what’s happening.”",
            "That includes being aware of the social, societal, and ethical implications of machine learning. “It's important to engage and begin to understand these tools, and then think about how you're going to use them well. We have to use these [tools] for the good of everybody,” said Dr. Joan LaRovere, MBA ’16, a pediatric cardiac intensive care physician and co-founder of the nonprofit The Virtue Foundation. “AI has so much potential to do good, and we need to really keep that in our lenses as we're thinking about this. How do we use this to do good and better the world?”",
            "Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior. Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems.",
            "The goal of AI is to create computer models that exhibit “intelligent behaviors” like humans, according to Boris Katz, a principal research scientist and head of the InfoLab Group at CSAIL. This means machines that can recognize a visual scene, understand a text written in natural language, or perform an action in the physical world.",
            "Machine learning is one way to use AI. It was defined in the 1950s by AI pioneer Arthur Samuel as “the field of study that gives computers the ability to learn without explicitly being programmed.”",
            "The definition holds true, according toMikey Shulman, a lecturer at MIT Sloan and head of machine learning at Kensho, which specializes in artificial intelligence for the finance and U.S. intelligence communities. He compared the traditional way of programming computers, or “software 1.0,” to baking, where a recipe calls for precise amounts of ingredients and tells the baker to mix for an exact amount of time. Traditional programming similarly requires creating detailed instructions for the computer to follow.",
            "But in some cases, writing a program for the machine to follow is time-consuming or impossible, such as training a computer to recognize pictures of different people. While humans can do this task easily, it’s difficult to tell a computer how to do it. Machine learning takes the approach of letting computers learn to program themselves through experience.",
            "Machine learning starts with data — numbers, photos, or text, like bank transactions, pictures of people or even bakery items, repair records, time series data from sensors, or sales reports. The data is gathered and prepared to be used as training data, or the information the machine learning model will be trained on. The more data, the better the program.",
            "From there, programmers choose a machine learning model to use, supply the data, and let the computer model train itself to find patterns or make predictions. Over time the human programmer can also tweak the model, including changing its parameters, to help push it toward more accurate results. (Research scientist Janelle Shane’s website AI Weirdness is an entertaining look at how machine learning algorithms learn and how they can get things wrong — as happened when an algorithm tried to generate recipes and created Chocolate Chicken Chicken Cake.)",
            "Some data is held out from the training data to be used as evaluation data, which tests how accurate the machine learning model is when it is shown new data. The result is a model that can be used in the future with different sets of data.",
            "Successful machine learning algorithms can do different things, Malone wrote in a recent research brief about AI and the future of work that was co-authored by MIT professor and CSAIL director Daniela Rus and Robert Laubacher, the associate director of the MIT Center for Collective Intelligence.",
            "“The function of a machine learning system can be descriptive, meaning that the system uses the data to explain what happened; predictive, meaning the system uses the data to predict what will happen; or prescriptive, meaning the system will use the data to make suggestions about what action to take,” the researchers wrote.",
            "There are three subcategories of machine learning:",
            "Supervised machine learning models are trained with labeled data sets, which allow the models to learn and grow more accurate over time. For example, an algorithm would be trained with pictures of dogs and other things, all labeled by humans, and the machine would learn ways to identify pictures of dogs on its own. Supervised machine learning is the most common type used today.",
            "In unsupervised machine learning, a program looks for patterns in unlabeled data. Unsupervised machine learning can find patterns or trends that people aren’t explicitly looking for. For example, an unsupervised machine learning program could look through online sales data and identify different types of clients making purchases.",
            "Reinforcement machine learning trains machines through trial and error to take the best action by establishing a reward system. Reinforcement learning can train models to play games or train autonomous vehicles to drive by telling the machine when it made the right decisions, which helps it learn over time what actions it should take.",
            "Source: Thomas Malone | MIT Sloan. See: https://bit.ly/3gvRho2, Figure 2.",
            "In the Work of the Future brief, Malone noted that machine learning is best suited for situations with lots of data — thousands or millions of examples, like recordings from previous conversations with customers, sensor logs from machines, or ATM transactions. For example, Google Translate was possible because it “trained” on the vast amount of information on the web, in different languages.",
            "In some cases, machine learning can gain insight or automate decision-making in cases where humans would not be able to, Madry said. “It may not only be more efficient and less costly to have an algorithm do this, but sometimes humans just literally are not able to do it,” he said.",
            "Google search is an example of something that humans can do, but never at the scale and speed at which the Google models are able to show potential answers every time a person types in a query, Malone said. “That’s not an example of computers putting people out of work. It's an example of computers doing things that would not have been remotely economically feasible if they had to be done by humans.”",
            "Machine learning is also associated with several other artificial intelligence subfields:",
            "Natural language processing",
            "Natural language processing is a field of machine learning in which machines learn to understand natural language as spoken and written by humans, instead of the data and numbers normally used to program computers. This allows machines to recognize language, understand it, and respond to it, as well as create new text and translate between languages. Natural language processing enables familiar technology like chatbots and digital assistants like Siri or Alexa.",
            "Neural networks",
            "Neural networks are a commonly used, specific class of machine learning algorithms. Artificial neural networks are modeled on the human brain, in which thousands or millions of processing nodes are interconnected and organized into layers.",
            "In an artificial neural network, cells, or nodes, are connected, with each cell processing inputs and producing an output that is sent to other neurons. Labeled data moves through the nodes, or cells, with each cell performing a different function. In a neural network trained to identify whether a picture contains a cat or not, the different nodes would assess the information and arrive at an output that indicates whether a picture features a cat.",
            "Deep learning",
            "Deep learning networks are neural networks with many layers. The layered network can process extensive amounts of data and determine the “weight” of each link in the network — for example, in an image recognition system, some layers of the neural network might detect individual features of a face, like eyes, nose, or mouth, while another layer would be able to tell whether those features appear in a way that indicates a face.",
            "Like neural networks, deep learning is modeled on the way the human brain works and powers many machine learning uses, like autonomous vehicles, chatbots, and medical diagnostics.",
            "“The more layers you have, the more potential you have for doing complex things well,” Malone said.",
            "Deep learning requires a great deal of computing power, which raises concerns about its economic and environmental sustainability.",
            "Machine learning is the core of some companies’ business models, like in the case of Netflix’s suggestions algorithm or Google’s search engine. Other companies are engaging deeply with machine learning, though it’s not their main business proposition.",
            "Others are still trying to determine how to use machine learning in a beneficial way. “In my opinion, one of the hardest problems in machine learning is figuring out what problems I can solve with machine learning,” Shulman said. “There’s still a gap in the understanding.”",
            "In person at MIT Sloan",
            "Register Now",
            "In a 2018 paper, researchers from the MIT Initiative on the Digital Economy outlined a 21-question rubric to determine whether a task is suitable for machine learning. The researchers found that no occupation will be untouched by machine learning, but no occupation is likely to be completely taken over by it. The way to unleash machine learning success, the researchers found, was to reorganize jobs into discrete tasks, some which can be done by machine learning, and others that require a human.",
            "Companies are already using machine learning in several ways, including:",
            "Recommendation algorithms. The recommendation engines behind Netflix and YouTube suggestions, what information appears on your Facebook feed, and product recommendations are fueled by machine learning. “[The algorithms] are trying to learn our preferences,” Madry said. “They want to learn, like on Twitter, what tweets we want them to show us, on Facebook, what ads to display, what posts or liked content to share with us.”",
            "Image analysis and object detection. Machine learning can analyze images for different information, like learning to identify people and tell them apart — though facial recognition algorithms are controversial. Business uses for this vary. Shulman noted that hedge funds famously use machine learning to analyze the number of cars in parking lots, which helps them learn how companies are performing and make good bets.",
            "Fraud detection. Machines can analyze patterns, like how someone normally spends or where they normally shop, to identify potentially fraudulent credit card transactions, log-in attempts, or spam emails.",
            "Automatic helplines or chatbots. Many companies are deploying online chatbots, in which customers or clients don’t speak to humans, but instead interact with a machine. These algorithms use machine learning and natural language processing, with the bots learning from records of past conversations to come up with appropriate responses.",
            "Self-driving cars. Much of the technology behind self-driving cars is based on machine learning, deep learning in particular.",
            "Medical imaging and diagnostics. Machine learning programs can be trained to examine medical images or other information and look for certain markers of illness, like a tool that can predict cancer risk based on a mammogram.",
            "Read report: Artificial Intelligence and the Future of Work",
            "While machine learning is fueling technology that can help workers or open new possibilities for businesses, there are several things business leaders should know about machine learning and its limits.",
            "Explainability",
            "One area of concern is what some experts call explainability, or the ability to be clear about what the machine learning models are doing and how they make decisions. “Understanding why a model does what it does is actually a very difficult question, and you always have to ask yourself that,” Madry said. “You should never treat this as a black box, that just comes as an oracle … yes, you should use it, but then try to get a feeling of what are the rules of thumb that it came up with? And then validate them.”",
            "This is especially important because systems can be fooled and undermined, or just fail on certain tasks, even those humans can perform easily. For example, adjusting the metadata in images can confuse computers — with a few adjustments, a machine identifies a picture of a dog as an ostrich.",
            "Madry pointed out another example in which a machine learning algorithm examining X-rays seemed to outperform physicians. But it turned out the algorithm was correlating results with the machines that took the image, not necessarily the image itself. Tuberculosis is more common in developing countries, which tend to have older machines. The machine learning program learned that if the X-ray was taken on an older machine, the patient was more likely to have tuberculosis. It completed the task, but not in the way the programmers intended or would find useful.",
            "The importance of explaining how a model is working — and its accuracy — can vary depending on how it’s being used, Shulman said. While most well-posed problems can be solved through machine learning, he said, people should assume right now that the models only perform to about 95% of human accuracy. It might be okay with the programmer and the viewer if an algorithm recommending movies is 95% accurate, but that level of accuracy wouldn’t be enough for a self-driving vehicle or a program designed to find serious flaws in machinery.",
            "Bias and unintended outcomes",
            "Machines are trained by humans, and human biases can be incorporated into algorithms — if biased information, or data that reflects existing inequities, is fed to a machine learning program, the program will learn to replicate it and perpetuate forms of discrimination. Chatbots trained on how people converse on Twitter can pick up on offensive and racist language, for example.",
            "In some cases, machine learning models create or exacerbate social problems. For example, Facebook has used machine learning as a tool to show users ads and content that will interest and engage them — which has led to models showing people extreme content that leads to polarization and the spread of conspiracy theories when people are shown incendiary, partisan, or inaccurate content.",
            "Ways to fight against bias in machine learning including carefully vetting training data and putting organizational support behind ethical artificial intelligence efforts, like making sure your organization embraces human-centered AI, the practice of seeking input from people of different backgrounds, experiences, and lifestyles when designing AI systems. Initiatives working on this issue include the Algorithmic Justice League and The Moral Machine project.",
            "Shulman said executives tend to struggle with understanding where machine learning can actually add value to their company. What’s gimmicky for one company is core to another, and businesses should avoid trends and find business use cases that work for them.",
            "The way machine learning works for Amazon is probably not going to translate at a car company, Shulman said — while Amazon has found success with voice assistants and voice-operated speakers, that doesn’t mean car companies should prioritize adding speakers to cars. More likely, he said, the car company might find a way to use machine learning on the factory line that saves or makes a great deal of money.",
            "“The field is moving so quickly, and that's awesome, but it makes it hard for executives to make decisions about it and to decide how much resourcing to pour into it,” Shulman said.",
            "It’s also best to avoid looking at machine learning as a solution in search of a problem, Shulman said. Some companies might end up trying to backport machine learning into a business use. Instead of starting with a focus on technology, businesses should start with a focus on a business problem or customer need that could be met with machine learning.",
            "A basic understanding of machine learning is important, LaRovere said, but finding the right machine learning use ultimately rests on people with different expertise working together. “I'm not a data scientist. I'm not doing the actual data engineering work — all the data acquisition, processing, and wrangling to enable machine learning applications — but I understand it well enough to be able to work with those teams to get the answers we need and have the impact we need,” she said. “You really have to work in a team.”",
            "Sign-up for a Machine Learning in Business Course.",
            "Watch an Introduction to Machine Learning through MIT OpenCourseWare.",
            "Read about how an AI pioneer thinks companies can use machine learning to transform.",
            "Watch a discussion with two AI experts about machine learning strides and limitations.",
            "Take a look at the seven steps of machine learning.",
            "Read next: 7 lessons for successful machine learning projects",
            "The mission of the MIT Sloan School of Management is to develop principled, innovative leaders who improve the world and to generate ideas that advance management practice."
        ]
    },
    {
        "url": "https://en.wikipedia.org/wiki/Machine_learning",
        "title": "Machine learning - Wikipedia",
        "content": [
            "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.[1] Advances in the field of deep learning have allowed neural networks to surpass many previous approaches in performance.[2]",
            "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine.[3][4] The application of ML to business problems is known as predictive analytics.",
            "Statistics and mathematical optimization (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.[6][7]",
            "From a theoretical viewpoint, probably approximately correct (PAC) learning provides a framework for describing machine learning.",
            "The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym self-teaching computers was also used in this time period.[10][11]",
            "Although the earliest machine learning model was introduced in the 1950s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side, the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.[12] In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells.[13] Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data.[12] Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.[12]",
            "By the early 1960s, an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognize patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions.[14] A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.[15] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[16] In 1981 a report was given on using teaching strategies so that an artificial neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[17]",
            "Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E.\"[18] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".[19]",
            "Modern-day machine learning has two objectives.  One is to classify data based on models which have been developed; the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.[20]",
            "As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics.[22] Probabilistic reasoning was also employed, especially in automated medical diagnosis.[23]: 488",
            "However, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.[23]: 488  By 1980, expert systems had come to dominate AI, and statistics was out of favor.[24] Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming(ILP), but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.[23]: 708–710, 755  Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \"connectionism\", by researchers from other disciplines including John Hopfield, David Rumelhart, and Geoffrey Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.[23]: 25",
            "Machine learning (ML), reorganized and recognized as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic, and probability theory.[24]",
            "There is a close connection between machine learning and compression. A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression (by using arithmetic coding on the output distribution). Conversely, an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as a justification for using data compression as a benchmark for \"general intelligence\".[25][26][27]",
            "An alternative view can show compression algorithms implicitly map strings into implicit feature space vectors, and compression-based similarity measures compute similarity within these feature spaces. For each compressor C(.) we define an associated vector space ℵ, such that C(.) maps an input string x, corresponding to the vector norm ||~x||. An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space; instead, feature vectors chooses to examine three representative lossless compression methods, LZW, LZ77, and PPM.[28]",
            "According to AIXI theory, a connection more directly explained in Hutter Prize, the best possible compression of x is the smallest possible software that generates x. For example, in that model, a zip file's compressed size includes both the zip file and the unzipping software, since you can not unzip it without both, but there may be an even smaller combined form.",
            "Examples of AI-powered audio/video compression software include NVIDIA Maxine, AIVC.[29] Examples of software that can perform AI-powered image compression include OpenCV, TensorFlow, MATLAB's Image Processing Toolbox (IPT) and High-Fidelity Generative Image Compression.[30]",
            "In unsupervised machine learning, k-means clustering can be utilized to compress data by grouping similar data points into clusters. This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as image compression.[31]",
            "Data compression aims to reduce the size of data files, enhancing storage efficiency and speeding up data transmission. K-means clustering, an unsupervised machine learning algorithm, is employed to partition a dataset into a specified number of clusters, k, each represented by the centroid of its points. This process condenses extensive datasets into a more compact set of representative points. Particularly beneficial in image and signal processing, k-means clustering aids in data reduction by replacing groups of data points with their centroids, thereby preserving the core information of the original data while significantly decreasing the required storage space.[32]",
            "Machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"unsupervised learning\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.",
            "Machine learning also has intimate ties to optimization: Many learning problems are formulated as minimization of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the preassigned labels of a set of examples).[34]",
            "Characterizing the generalization of various learning algorithms is an active topic of current research, especially for deep learning algorithms.",
            "Machine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample, while machine learning finds generalizable predictive patterns.[35] According to Michael I. Jordan, the ideas of machine learning, from methodological principles to theoretical tools, have had a long pre-history in statistics.[36] He also suggested the term data science as a placeholder to call the overall field.[36]",
            "Conventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.[37]",
            "Leo Breiman distinguished two statistical modeling paradigms: data model and algorithmic model,[38] wherein \"algorithmic model\" means more or less the machine learning algorithms like Random Forest.",
            "Some statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.[39]",
            "Analytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyze the weight space of deep neural networks.[40] Statistical physics is thus finding applications in the area of medical diagnostics.[41]",
            "A core objective of a learner is to generalize from its experience.[5][42] Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.",
            "The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the Probably Approximately Correct Learning (PAC) model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalization error.",
            "For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.[43]",
            "In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.",
            "Machine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \"signal\" or \"feedback\" available to the learning system:",
            "Although each algorithm has advantages and limitations, no single algorithm works for all problems.[44][45][46]",
            "Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.[47] The data, known as training data, consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector, and the training data is represented by a matrix. Through iterative optimization of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.[48] An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.[18]",
            "Types of supervised-learning algorithms include active learning, classification and regression.[49] Classification algorithms are used when the outputs are restricted to a limited set of values, and regression algorithms are used when the outputs may have any numerical value within a range. As an example, for a classification algorithm that filters emails, the input would be an incoming email, and the output would be the name of the folder in which to file the email. Examples of regression would be predicting the height of a person, or the future temperature. [50]",
            "Similarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification.",
            "Unsupervised learning algorithms find structures in data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering, dimensionality reduction,[7] and density estimation.[51]",
            "Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity.",
            "A special type of unsupervised learning called, self-supervised learning involves training a model by generating the supervisory signal from the data itself.[52][53]",
            "Semi-supervised learning falls between unsupervised learning (without any labeled training data) and supervised learning (with completely labeled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data, can produce a considerable improvement in learning accuracy.",
            "In weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.[54]",
            "Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcements learning algorithms use dynamic programming techniques.[55] Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.",
            "Dimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables.[56] In other words, it is a process of reducing the dimension of the feature set, also called the \"number of features\". Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction. One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D).\nThe manifold hypothesis proposes that high-dimensional data sets lie along low-dimensional manifolds, and many dimensionality reduction techniques make this assumption, leading to the area of manifold learning and manifold regularization.",
            "Other approaches have been developed which do not fit neatly into this three-fold categorization, and sometimes more than one is used by the same machine learning system. For example, topic modeling, meta-learning.[57]",
            "Self-learning, as a machine learning paradigm was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA).[58] It is learning with no external rewards and no external teacher advice. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.[59]\nThe self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine:",
            "It is a system with only one input, situation, and only one output, action (or behavior) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioral environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioral environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behavior, in an environment that contains both desirable and undesirable situations.[60]",
            "Several learning algorithms aim at discovering better representations of the inputs provided during training.[61] Classic examples include principal component analysis and cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual feature engineering, and allows a machine to both learn the features and use them to perform a specific task.",
            "Feature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labeled input data. Examples include artificial neural networks, multilayer perceptrons, and supervised dictionary learning. In unsupervised feature learning, features are learned with unlabeled input data.  Examples include dictionary learning, independent component analysis, autoencoders, matrix factorization[62] and various forms of clustering.[63][64][65]",
            "Manifold learning algorithms attempt to do so under the constraint that the learned representation is low-dimensional. Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros. Multilinear subspace learning algorithms aim to learn low-dimensional representations directly from tensor representations for multidimensional data, without reshaping them into higher-dimensional vectors.[66] Deep learning algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data.[67]",
            "Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data has not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms.",
            "Sparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix. The method is strongly NP-hard and difficult to solve approximately.[68] A popular heuristic method for sparse dictionary learning is the k-SVD algorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image de-noising. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.[69]",
            "In data mining, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.[70] Typically, the anomalous items represent an issue such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are referred to as outliers, novelties, noise, deviations and exceptions.[71]",
            "In particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.[72]",
            "Three broad categories of anomaly detection techniques exist.[73] Unsupervised anomaly detection techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labeled as \"normal\" and \"abnormal\" and involves training a classifier (the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behavior from a given normal training data set and then test the likelihood of a test instance to be generated by the model.",
            "Robot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning,[74][75] and finally meta-learning (e.g. MAML).",
            "Association rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of \"interestingness\".[76]",
            "Rule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \"rules\" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[77] Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems.",
            "Based on the concept of strong rules, Rakesh Agrawal, Tomasz Imieliński and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets.[78] For example, the rule \n\n\n\n{\n\no\nn\ni\no\nn\ns\n,\np\no\nt\na\nt\no\ne\ns\n\n}\n⇒\n{\n\nb\nu\nr\ng\ne\nr\n\n}\n\n\n{\\displaystyle \\{\\mathrm {onions,potatoes} \\}\\Rightarrow \\{\\mathrm {burger} \\}}\n\n found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements. In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.",
            "Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions.[79]",
            "Inductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs.",
            "Inductive logic programming is particularly useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting.[80][81][82] Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples.[83] The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction, proving a property for all members of a well-ordered set.",
            "A machine learning model is a type of mathematical model that, once \"trained\" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimize errors in its predictions.[84] By extension, the term \"model\" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.[85]",
            "Various types of models have been used and researched for machine learning systems, picking the best model for a task is called model selection.",
            "Artificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.",
            "An ANN is a model based on a collection of connected units or nodes called \"artificial neurons\", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a \"signal\", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called \"edges\". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.",
            "The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.",
            "Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[86]",
            "Decision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making.",
            "Support-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.[87] An SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.",
            "Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularization methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel[88]), logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space.",
            "A Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences, are called dynamic Bayesian networks. Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.",
            "A Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution, and it relies on a pre-defined covariance function, or kernel, that models how pairs of points relate to each other depending on their locations.",
            "Given a set of observed points, or input–output examples, the distribution of the (unobserved) output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new, unobserved point.",
            "Gaussian processes are popular surrogate models in Bayesian optimization used to do hyperparameter optimization.",
            "A genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.[90][91] Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.[92]",
            "The theory of belief functions, also referred to as evidence theory or Dempster–Shafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as probability, possibility and  imprecise probability theories. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g.,  Dempster's rule of combination), just like how in a pmf-based Bayesian approach[clarification needed] would combine probabilities. However, there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and uncertainty quantification. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner's decision boundary, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving.[4][9] However, the computational complexity of these algorithms are dependent on the number of propositions (classes), and can lead to a much higher computation time when compared to other machine learning approaches.",
            "Typically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data. Data from the training set can be as varied as a corpus of text, a collection of images, sensor data, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and notably, becoming integrated within machine learning engineering teams.",
            "Federated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralizes the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralized server. This also increases efficiency by decentralizing the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to Google.[93]",
            "There are many applications for machine learning, including:",
            "In 2006, the media-services provider Netflix held the first \"Netflix Prize\" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million.[96] Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (\"everything is a recommendation\") and they changed their recommendation engine accordingly.[97] In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis.[98] In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software.[99] In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists.[100] In 2019 Springer Nature published the first research book created using machine learning.[101] In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19.[102] Machine learning was recently applied to predict the pro-environmental behavior of travelers.[103] Recently, machine learning technology was also applied to optimize smartphone's performance and thermal behavior based on the user's interaction with the phone.[104][105][106] When applied correctly, machine learning algorithms (MLAs) can utilize a wide range of company characteristics to predict stock returns without overfitting. By employing effective feature engineering and combining forecasts, MLAs can generate results that far surpass those obtained from basic linear techniques like OLS.[107]",
            "Recent advancements in machine learning have extended into the field of quantum chemistry, where novel algorithms now enable the prediction of solvent effects on chemical reactions, thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes.[108]",
            "Machine Learning is becoming a useful tool to investigate and predict evacuation decision making in large scale and small scale disasters. Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes.[109][110][111] Other applications have been focusing on pre evacuation decisions in building fires.[112][113]",
            "Although machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results.[114][115][116] Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.[117]",
            "The \"black box theory\" poses another yet significant challenge. Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque, meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted out of the data.[118] The House of Lords Select Committee, which claimed that such an \"intelligence system\" that could have a \"substantial impact on an individual's life\" would not be considered acceptable unless it provided \"a full and satisfactory explanation for the decisions\" it makes.[118]",
            "In 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision.[119] Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested.[120][121] Microsoft's Bing Chat chatbot has been reported to produce hostile and offensive response against its users.[122]",
            "Machine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves.[123]",
            "Explainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial intelligence (AI) in which humans can understand the decisions or predictions made by the AI.[124] It contrasts with the \"black box\" concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision.[125] By refining the mental models of users of AI-powered systems and dismantling their misconceptions, XAI promises to help users perform more effectively. XAI may be an implementation of the social right to explanation.",
            "Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalizing the theory in accordance with how complex the theory is.[126]",
            "Learners can also disappoint by \"learning the wrong lesson\". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses.[127] A real-world example is that, unlike humans, current image classifiers often do not primarily make judgments from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in \"adversarial\" images that the system misclassifies.[128][129]",
            "Adversarial vulnerabilities can also result in nonlinear systems, or from non-pattern perturbations. For some systems, it is possible to change the output by only changing a single adversarially chosen pixel.[130] Machine learning models are often vulnerable to manipulation and/or evasion via adversarial machine learning.[131]",
            "Researchers have demonstrated how backdoors can be placed undetectably into classifying (e.g., for categories \"spam\" and well-visible \"not spam\" of posts) machine learning models that are often developed and/or trained by third parties. Parties can change the classification of any input, including in cases for which a type of data/software transparency is provided, possibly including white-box access.[132][133][134]",
            "Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.[135]",
            "In addition to overall accuracy, investigators frequently report sensitivity and specificity meaning true positive rate (TPR) and true negative rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. Receiver operating characteristic (ROC) along with the accompanying Area Under the ROC Curve (AUC) offer additional tools for classification model assessment. Higher AUC is associated with a better performing model.[136]",
            "The ethics of artificial intelligence covers a broad range of topics within the field that are considered to have particular ethical stakes.[137] This includes algorithmic biases, fairness, automated decision-making, accountability, privacy, and regulation. \nIt also covers various emerging or potential future challenges such as machine ethics (how to make machines that behave ethically), lethal autonomous weapon systems, arms race dynamics, AI safety and alignment, technological unemployment, AI-enabled misinformation, how to treat certain AI systems if they have a moral status (AI welfare and rights), artificial superintelligence and existential risks.[137]",
            "Different machine learning approaches can suffer from different data biases. A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.[138]",
            "Systems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitizing cultural prejudices.[139] For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and that this program had denied nearly 60 candidates who were found to either be women or have non-European sounding names.[138] Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants.[140][141] Another example includes predictive policing company Geolitica's predictive algorithm that resulted in \"disproportionately high levels of over-policing in low-income and minority communities\" after being trained with historical crime data.[142]",
            "While responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning, some researchers blame lack of participation and representation of minority population in the field of AI for machine learning's vulnerability to biases.[143] In fact, according to research carried out by the Computing Research Association (CRA) in 2021, \"female faculty merely make up 16.1%\" of all faculty members who focus on AI among several universities around the world.[144] Furthermore, among the group of \"new U.S. resident AI PhD graduates,\" 45% identified as white, 22.4% as Asian, 3.2% as Hispanic, and 2.4% as African American, which further demonstrates a lack of diversity in the field of AI.[144]",
            "Language models learned from data have been shown to contain human-like biases.[145][146] Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.[147][148] In 2016, Microsoft tested Tay, a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.[149]",
            "In an experiment carried out by ProPublica, an investigative journalism organization, a machine learning algorithm's insight into the recidivism rates among prisoners falsely flagged \"black defendants high risk twice as often as white defendants.\"[142] In 2015, Google Photos once tagged a couple of black people as gorillas, which caused controversy. The gorilla label was subsequently removed, and in 2023, it still cannot recognize gorillas.[150] Similar issues with recognizing non-white people have been found in many other systems.[151]",
            "Because of such challenges, the effective use of machine learning may take longer to be adopted in other domains.[152] Concern for fairness in machine learning, that is, reducing bias in machine learning and propelling its use for human good, is increasingly expressed by artificial intelligence scientists, including Fei-Fei Li, who said that \"[t]here's nothing artificial about AI. It's inspired by people, it's created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.\"[153]",
            "There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is potential for machine learning in health care to provide professionals an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.[154]",
            "Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of nonlinear hidden units.[155] By 2019, graphics processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.[156] OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.[157][158]",
            "Neuromorphic computing refers to a class of computing systems designed to emulate the structure and functionality of biological neural networks. These systems may be implemented through software-based simulations on conventional hardware or through specialized hardware architectures.[159]",
            "A physical neural network is a specific type of neuromorphic hardware that relies on electrically adjustable materials, such as memristors, to emulate the function of neural synapses. The term \"physical neural network\" highlights the use of physical hardware for computation, as opposed to software-based implementations. It broadly refers to artificial neural networks that use materials with adjustable resistance to replicate neural synapses.[160][161]",
            "Embedded machine learning is a sub-field of machine learning where models are deployed on embedded systems with limited computing resources, such as wearable computers, edge devices and microcontrollers.[162][163][164] Running models directly on these devices eliminates the need to transfer and store data on cloud servers for further processing, thereby reducing the risk of data breaches, privacy leaks and theft of intellectual property, personal data and business secrets. Embedded machine learning can be achieved through various techniques, such as hardware acceleration,[165][166] approximate computing,[167] and model optimization.[168][169] Common optimization techniques include pruning, quantization, knowledge distillation, low-rank factorization, network architecture search, and parameter sharing.",
            "Software suites containing a variety of machine learning algorithms include the following:"
        ]
    },
    {
        "url": "https://developers.google.com/machine-learning/crash-course",
        "title": "Machine Learning  |  Google for Developers",
        "content": [
            "These modules cover the fundamentals of building regression and classification\n   models.",
            "These modules cover fundamental techniques and best practices for working with machine learning data.",
            "These modules cover advanced ML model architectures.",
            "These modules cover critical considerations when building and deploying ML models in the real world, including productionization best practices, automation, and responsible engineering."
        ]
    },
    {
        "url": "https://aws.amazon.com/what-is/machine-learning/",
        "title": "What is Machine Learning? - ML Technology Explained - AWS",
        "content": [
            "Machine learning is a type of artificial intelligence that performs data analysis tasks without explicit instructions. Machine learning technology can process large quantities of historical data, identify patterns, and predict new relationships between previously unknown data. You can perform classification and prediction tasks on documents, images, numbers, and other data types.",
            "For example, a financial organization could train a machine learning system to classify fraudulent and genuine transactions. The system identifies patterns in known data to accurately guess or predict whether a new transaction is genuine.",
            "While the terms machine learning and artificial intelligence (AI) are used interchangeably, they are not the same. Machine learning is one of many branches of AI. While machine learning is AI, not all AI activities can be called machine learning.",
            "Artificial intelligence is an umbrella term for different strategies and techniques used to make machines more human-like. AI includes everything from smart assistants like Alexa, chatbots, and image generators to robotic vacuum cleaners and self-driving cars.",
            "In contrast, machine learning models perform more specific data analysis tasks—like classifying documents, labeling images, or predicting the maintenance schedule of factory equipment. Machine learning technology is primarily based on mathematics and statistics, while other types of AI are more complex.",
            "Learn more about machine learning vs. artificial intelligence",
            "Let’s take a look at machine learning applications in some key industries.",
            "Machine learning can support predictive maintenance, quality control, and innovative research in the manufacturing sector. It also helps companies improve logistical solutions, including assets, supply chain, and inventory management. For example, manufacturing giant 3M uses machine learning to innovate sandpaper. Machine learning algorithms enable 3M researchers to analyze how slight changes in shape, size, and orientation improve abrasiveness and durability. Those suggestions inform the manufacturing process.",
            "The proliferation of wearable sensors and devices has generated significant health data. Machine learning programs analyze this information and support doctors in real-time diagnosis and treatment. Machine learning researchers are developing solutions that detect cancerous tumors and diagnose eye diseases, significantly impacting human health outcomes. For example, Cambia Health Solutions uses machine learning to automate and customize treatment for pregnant women.",
            "Financial machine learning projects improve risk analytics and regulation. Machine learning technology allows investors to identify new opportunities by analyzing stock market movements, evaluating hedge funds, or calibrating financial portfolios. In addition, it can help identify high-risk loan clients and mitigate signs of fraud. For example, NerdWallet, a personal finance company, uses machine learning to compare financial products like credit cards, banking, and loans.",
            "Retail can use machine learning to improve customer service, stock management, upselling, and cross-channel marketing. For example, Amazon Fulfillment (AFT) cut infrastructure costs by 40 percent using a machine learning model to identify misplaced inventory. This helps them deliver on Amazon’s promise that an item will be readily available to customers and arrive on time despite processing millions of global shipments annually.",
            "Entertainment companies turn to machine learning to better understand their target audiences and deliver immersive, personalized, and on-demand content. Machine learning algorithms are deployed to help design trailers and other advertisements, provide consumers with personalized content recommendations, and even streamline production.",
            "For example, Disney uses machine learning to archive its media library. Machine learning tools automatically tag, describe, and sort media content, enabling Disney writers and animators to quickly search for and familiarize themselves with Disney characters.",
            "If a system’s output is predictable, then it is said to be deterministic. Most software applications respond predictably to the user's action, so you can say: “If the user does this, he gets that.” However, machine learning algorithms learn through observation along with experiences. Therefore, they are probabilistic in nature. The statement now changes to: “If the user does this, there is an X% chance of that happening.”  In machine learning, determinism is a strategy used while applying the learning methods described above. Any of the supervised, unsupervised, and other training methods can be made deterministic depending on the business's desired outcomes. The research question, data retrieval, structure, and storage decisions determine if a deterministic or non-deterministic strategy is adopted.",
            "Deterministic vs. probabilistic approach",
            "The deterministic approach focuses on the accuracy and the amount of data collected, so efficiency is prioritized over uncertainty. On the other hand, the non-deterministic (or probabilistic) process is designed to manage the chance factor. Built-in tools are integrated into machine learning algorithms to help quantify, identify, and measure uncertainty during learning and observation.",
            "Machine learning requires a strong foundation in mathematics, statistics, coding, and data technologies. Those wishing to advance in machine learning should consider completing a master's degree in artificial intelligence or data science. These programs typically involve topics such as neural networks, natural language processing, and computer vision in-depth.",
            "However, formal education isn’t the only path. You can use online courses to learn at your own pace and master specific skills. Machine learning training on AWS includes certifications by AWS experts on topics like:",
            "Getting started with machine learning requires implementing the machine learning lifecycle. It contains the following phases.",
            "An organization considering machine learning should first identify the problems it wants to solve. Identify the business value you gain by using machine learning in problem-solving. Can you measure the business value using specific success criteria for business objectives? A goal-oriented approach helps you justify expenditures and convince key stakeholders.",
            "Next, frame the business problem as a machine learning problem. Identify what is observed and what should be predicted. A key step in this phase is to determine what to predict and how to optimize related performance and error metrics.",
            "Data processing converts data into a usable format using machine learning algorithms. It includes identifying, collecting, and preprocessing data along with feature engineering. You create, transform, extract, and select machine-learning variables from your data.",
            "This is the core process of training, tuning, and evaluating your model, as described in the previous section. It includes establishing MLOps. Machine learning operations (MLOps) are a set of practices that automate and simplify machine learning (ML) workflows and deployments. They unify ML development with deployment and operations. For example, you create a CI/CD pipeline that automates the build, train, and release to staging and production environments.",
            "A model monitoring system ensures your model maintains a desired performance level through early detection and mitigation. It includes collecting user feedback to maintain and improve the model so it remains relevant over time.",
            "AWS puts machine learning in the hands of every developer, data scientist, and business user. AWS Machine Learning services provide high-performing, cost-effective, and scalable infrastructure to meet business needs.",
            "Build, train, and deploy ML models at scale",
            "Quickly build scalable, secure deep learning applications in preconfigured environments",
            "Quickly deploy deep learning environments with optimized, prepackaged container images",
            "Train and deploy Hugging Face models in minutes",
            "Enhance and visualize deep learning applications with ML tools",
            "Leverage a highly performant, scalable, and enterprise-ready PyTorch experience on AWS",
            "Build ML applications that train quickly and run virtually anywhere",
            "A secure, scalable, and collaborative Jupyter experience on AWS"
        ]
    },
    {
        "url": "https://www.energy.gov/science/doe-explainsmachine-learning",
        "title": "DOE Explains...Machine Learning | Department of Energy",
        "content": [
            "An official website of the United States government",
            "Here's how you know",
            "Official websites use .gov\n\n              A .gov website belongs to an official government organization in the United States.",
            "Secure .gov websites use HTTPS\n\n              A lock (   \n\nLock\nLocked padlock\n\n\n\n ) or https:// means you’ve safely connected to the .gov website. Share sensitive information only on official, secure websites.",
            "Machine learning is the process of using computers to detect patterns in massive datasets and then make predictions based on what the computer learns from those patterns. This makes machine learning a specific and narrow type of artificial intelligence. Full artificial intelligence involves machines that can perform abilities we associate with the minds of human beings and intelligent animals, such as perceiving, learning, and problem solving.",
            "All machine learning is based on algorithms. In general, algorithms are sets of specific instructions that a computer uses to solve problems. In machine learning, algorithms are rules for how to analyze data using statistics. Machine learning systems use these rules to identify relationships between data inputs and desired outputs–usually  predictions. To get started, scientists give machine learning systems a set of training data. The systems apply their algorithms to this data to train themselves how to analyze similar inputs they receive in the future.",
            "One area where machine learning shows huge promise is detecting cancer in computer tomography (CT) imaging. First, researchers assemble as many CT images as possible to use as training data. Some of these images show tissue with cancerous cells, and some show healthy tissues. Researchers also assemble information on what to look for in an image to identify cancer. For example, this might include what the boundaries of cancerous tumors look like. Next, they create rules on the relationship between data in the images and what doctors know about identifying cancer. Then they give these rules and the training data to the machine learning system. The system uses the rules and the training data to teach itself how to recognize cancerous tissue. Finally, the system gets a new patient’s CT images. Using what it has learned, the system decides which images show signs of cancer, faster than any human could. Doctors could use the system’s predictions to aid in the decision about whether a patient has cancer and how to treat it.",
            "The way training data is set up divides machine learning systems into two broad types: supervised and unsupervised. If the training data is labeled, the system is supervised. Labeled data tells the system what the data is. For example, CT images could be labeled to indicate cancerous lesions or tumors next to tissues that are healthy. Basically, this means the machine learning system learns by example. Labeling data can be very time consuming for the large amounts of data required for training datasets.",
            "If the training data is not labeled, the machine learning system is unsupervised. In the cancer scan example, an unsupervised machine learning system would be given a huge number of CT scans and information on tumor types, then left to teach itself what to look for to recognize cancer. This frees human beings from needing to label the data used in the training process. The disadvantage of unsupervised learning is that the results may not be as accurate because of the lack of explicit labels.",
            "Some machine learning systems can improve their abilities based on feedback received on the predictions. These are called reinforcement machine learning systems. For example, the system could be told the results of doctors’ other tests of whether patients have cancer or not. The system could then tweak its algorithms to produce more accurate predictions in the future.",
            "The Department of Energy Office of Science supports research on machine learning through its Advanced Scientific Computing Research (ASCR) program. ASCR has a portfolio of data management, data analysis, computer technology, and related research that all contribute to machine learning and artificial intelligence. As part of this portfolio, DOE owns some of the world’s most capable supercomputers.",
            "The DOE Office of Science as a whole is committed to the use of machine learning to support scientific research. Science depends on big data, and Office of Science user facilities such as particle accelerators and X-ray light sources generate mountains of it. Using machine learning, researchers are identifying patterns or designs in data from these facilities that are difficult or impossible for humans to detect, at speeds that are hundreds to thousands of times faster than traditional data analysis techniques.",
            "Scientific terms can be confusing. DOE Explains offers straightforward explanations of key words and concepts in fundamental science. It also describes how these concepts apply to the work that the Department of Energy’s Office of Science conducts as it helps the United States excel in research across the scientific spectrum.",
            "Powering cutting-edge projects & scientific innovations for a safe sustainable future.",
            "Follow Us",
            "Subscribe To Our Newsletter"
        ]
    },
    {
        "url": "https://www.techtarget.com/searchenterpriseai/definition/machine-learning-ML",
        "title": "What is Machine Learning? Guide, Definition and Examples",
        "content": [
            "Machine learning is a branch of AI focused on building computer systems that learn from data. The breadth of ML techniques enables software applications to improve their performance over time.",
            "ML algorithms are trained to find relationships and patterns in data. Using historical data as input, these algorithms can make predictions, classify information, cluster data points, reduce dimensionality and even generate new content. Examples of the latter, known as generative AI, include OpenAI's ChatGPT, Anthropic's Claude and GitHub Copilot.",
            "Machine learning is widely applicable across many industries. For example, e-commerce, social media and news organizations use recommendation engines to suggest content based on a customer's past behavior. In self-driving cars, ML algorithms and computer vision play a critical role in safe road navigation. In healthcare, ML can aid in diagnosis and suggest treatment plans. Other common ML use cases include fraud detection, spam filtering, malware threat detection, predictive maintenance and business process automation.",
            "While ML is a powerful tool for solving problems, improving business operations and automating tasks, it's also complex and resource-intensive, requiring deep expertise and significant data and infrastructure. Choosing the right algorithm for a task calls for a strong grasp of mathematics and statistics. Training ML algorithms often demands large amounts of high-quality data to produce accurate results. The results themselves, particularly those from complex algorithms such as deep neural networks, can be difficult to understand. And ML models can be costly to run and fine-tune.",
            "Still, most organizations are embracing machine learning, either directly or through ML-infused products. According to a 2024 report from Rackspace Technology, AI spending in 2024 is expected to more than double compared with 2023, and 86% of companies surveyed reported seeing gains from AI adoption. Companies reported using the technology to enhance customer experience (53%), innovate in product design (49%) and support human resources (47%), among other applications.",
            "TechTarget's guide to machine learning serves as a primer on this important field, explaining what machine learning is, how to implement it and its business applications. You'll find information on the various types of ML algorithms, challenges and best practices associated with developing and deploying ML models, and what the future holds for machine learning. Throughout the guide, there are hyperlinks to related articles that cover these topics in greater depth.",
            "ML has played an increasingly important role in human society since its beginnings in the mid-20th century, when AI pioneers like Walter Pitts, Warren McCulloch, Alan Turing and John von Neumann laid the field's computational groundwork. Training machines to learn from data and improve over time has enabled organizations to automate routine tasks -- which, in theory, frees humans to pursue more creative and strategic work.",
            "Machine learning has extensive and diverse practical applications. In finance, ML algorithms help banks detect fraudulent transactions by analyzing vast amounts of data in real time at a speed and accuracy humans cannot match. In healthcare, ML assists doctors in diagnosing diseases based on medical images and informs treatment plans with predictive models of patient outcomes. And in retail, many companies use ML to personalize shopping experiences, predict inventory needs and optimize supply chains.",
            "ML also performs manual tasks that are beyond human ability to execute at scale -- for example, processing the huge quantities of data generated daily by digital devices. This ability to extract patterns and insights from vast data sets has become a competitive differentiator in fields like banking and scientific discovery. Many of today's leading companies, including Meta, Google and Uber, integrate ML into their operations to inform decision-making and improve efficiency.",
            "Machine learning is necessary to make sense of the ever-growing volume of data generated by modern societies. The abundance of data humans create can also be used to further train and fine-tune ML models, accelerating advances in ML. This continuous learning loop underpins today's most advanced AI systems, with profound implications.",
            "Philosophically, the prospect of machines processing vast amounts of data challenges humans' understanding of our intelligence and our role in interpreting and acting on complex information. Practically, it raises important ethical considerations about the decisions made by advanced ML models. Transparency and explainability in ML training and decision-making, as well as these models' effects on employment and societal structures, are areas for ongoing oversight and discussion.",
            "Classical ML is often categorized by how an algorithm learns to become more accurate in its predictions. The four basic types of ML are:",
            "The choice of algorithm depends on the nature of the data. Many algorithms and techniques aren't limited to a single type of ML; they can be adapted to multiple types depending on the problem and data set. For instance, deep learning algorithms such as convolutional and recurrent neural networks are used in supervised, unsupervised and reinforcement learning tasks, based on the specific problem and data availability.",
            "Deep learning is a subfield of ML that focuses on models with multiple levels of neural networks, known as deep neural networks. These models can automatically learn and extract hierarchical features from data, making them effective for tasks such as image and speech recognition.",
            "Supervised learning supplies algorithms with labeled training data and defines which variables the algorithm should assess for correlations. Both the input and output of the algorithm are specified. Initially, most ML algorithms used supervised learning, but unsupervised approaches are gaining popularity.",
            "Supervised learning algorithms are used for numerous tasks, including the following:",
            "Unsupervised learning doesn't require labeled data. Instead, these algorithms analyze unlabeled data to identify patterns and group data points into subsets using techniques such as gradient descent. Most types of deep learning, including neural networks, are unsupervised algorithms.",
            "Unsupervised learning is effective for various tasks, including the following:",
            "Semisupervised learning provides an algorithm with only a small amount of labeled training data. From this data, the algorithm learns the dimensions of the data set, which it can then apply to new, unlabeled data. Note, however, that providing too little training data can lead to overfitting, where the model simply memorizes the training data rather than truly learning the underlying patterns.",
            "Although algorithms typically perform better when they train on labeled data sets, labeling can be time-consuming and expensive. Semisupervised learning combines elements of supervised learning and unsupervised learning, striking a balance between the former's superior performance and the latter's efficiency.",
            "Semisupervised learning can be used in the following areas, among others:",
            "Reinforcement learning involves programming an algorithm with a distinct goal and a set of rules to follow in achieving that goal. The algorithm seeks positive rewards for performing actions that move it closer to its goal and avoids punishments for performing actions that move it further from the goal.",
            "Reinforcement learning is often used for tasks such as the following:",
            "Developing the right ML model to solve a problem requires diligence, experimentation and creativity. Although the process can be complex, it can be summarized into a seven-step plan for building an ML model.",
            "1. Understand the business problem and define success criteria. Convert the group's knowledge of the business problem and project objectives into a suitable ML problem definition. Consider why the project requires machine learning, the best type of algorithm for the problem, any requirements for transparency and bias reduction, and expected inputs and outputs.",
            "2. Understand and identify data needs. Determine what data is necessary to build the model and assess its readiness for model ingestion. Consider how much data is needed, how it will be split into test and training sets, and whether a pretrained ML model can be used.",
            "3. Collect and prepare the data for model training. Clean and label the data, including replacing incorrect or missing data, reducing noise and removing ambiguity. This stage can also include enhancing and augmenting data and anonymizing personal data, depending on the data set. Finally, split the data into training, test and validation sets.",
            "4. Determine the model's features and train it. Start by selecting the appropriate algorithms and techniques, including setting hyperparameters. Next, train and validate the model, then optimize it as needed by adjusting hyperparameters and weights. Depending on the business problem, algorithms might include natural language understanding capabilities, such as recurrent neural networks or transformers for natural language processing (NLP) tasks, or boosting algorithms to optimize decision tree models.",
            "5. Evaluate the model's performance and establish benchmarks. Perform confusion matrix calculations, determine business KPIs and ML metrics, measure model quality, and determine whether the model meets business goals.",
            "6. Deploy the model and monitor its performance in production. This part of the process, known as operationalizing the model, is typically handled collaboratively by data scientists and machine learning engineers. Continuously measure model performance, develop benchmarks for future model iterations and iterate to improve overall performance. Deployment environments can be in the cloud, at the edge or on premises.",
            "7. Continuously refine and adjust the model in production. Even after the ML model is in production and continuously monitored, the job continues. Changes in business needs, technology capabilities and real-world data can introduce new demands and requirements.",
            "Learn how the following algorithms and techniques are used in training and optimizing machine learning models:",
            "Machine learning has become integral to business software. The following are some examples of how various business applications use ML:",
            "Enterprise adoption of ML techniques across industries is transforming business processes. Here are a few examples:",
            "When deployed effectively, ML provides a competitive advantage to businesses by identifying trends and predicting outcomes with higher accuracy than conventional statistics or human intelligence. ML can benefit businesses in several ways:",
            "But machine learning also entails a number of business challenges. First and foremost, it can be expensive. ML requires costly software, hardware and data management infrastructure, and ML projects are typically driven by data scientists and engineers who command high salaries.",
            "Another significant issue is ML bias. Algorithms trained on data sets that exclude certain populations or contain errors can lead to inaccurate models. These models can fail and, at worst, produce discriminatory outcomes. Basing core enterprise processes on biased models can cause businesses regulatory and reputational harm.",
            "Explaining the internal workings of a specific ML model can be challenging, especially when the model is complex. As machine learning evolves, the importance of explainable, transparent models will only grow, particularly in industries with heavy compliance burdens, such as banking and insurance.",
            "Developing ML models whose outcomes are understandable and explainable by human beings has become a priority due to rapid advances in and adoption of sophisticated ML techniques, such as generative AI. Researchers at AI labs such as Anthropic have made progress in understanding how generative AI models work, drawing on interpretability and explainability techniques.",
            "Interpretability focuses on understanding an ML model's inner workings in depth, whereas explainability involves describing the model's decision-making in an understandable way. Interpretable ML techniques are typically used by data scientists and other ML practitioners, where explainability is more often intended to help non-experts understand machine learning models. A so-called black box model might still be explainable even if it is not interpretable, for example. Researchers could test different inputs and observe the subsequent changes in outputs, using methods such as Shapley additive explanations (SHAP) to see which factors most influence the output. In this way, researchers can arrive at a clear picture of how the model makes decisions (explainability), even if they do not fully understand the mechanics of the complex neural network inside (interpretability).",
            "Interpretable ML techniques aim to make a model's decision-making process clearer and more transparent. Examples include decision trees, which provide a visual representation of decision paths; linear regression, which explains predictions based on weighted sums of input features; and Bayesian networks, which represent dependencies among variables in a structured and interpretable way.",
            "Explainable AI (XAI) techniques are used after the fact to make the output of more complex ML models more comprehensible to human observers. Examples include local interpretable model-agnostic explanations (LIME), which approximate the model's behavior locally with simpler models to explain individual predictions, and SHAP values, which assign importance scores to each feature to clarify how they contribute to the model's decision.",
            "In some industries, data scientists must use simple ML models because it's important for the business to explain how every decision was made. This need for transparency often results in a tradeoff between simplicity and accuracy. Although complex models can produce highly accurate predictions, explaining their outputs to a layperson -- or even an expert -- can be difficult.",
            "Simpler, more interpretable models are often preferred in highly regulated industries where decisions must be justified and audited. But advances in interpretability and XAI techniques are making it increasingly feasible to deploy complex models while maintaining the transparency necessary for compliance and trust.",
            "Building an ML team starts with defining the goals and scope of the ML project. Essential questions to ask include: What business problems does the ML team need to solve? What are the team's objectives? What metrics will be used to assess performance?",
            "Answering these questions is an essential part of planning a machine learning project. It helps the organization understand the project's focus (e.g., research, product development, data analysis) and the types of ML expertise required (e.g., computer vision, NLP, predictive modeling).",
            "Next, based on these considerations and budget constraints, organizations must decide what job roles will be necessary for the ML team. The project budget should include not just standard HR costs, such as salaries, benefits and onboarding, but also ML tools, infrastructure and training. While the specific composition of an ML team will vary, most enterprise ML teams will include a mix of technical and business professionals, each contributing an area of expertise to the project.",
            "An ML team typically includes some non-ML roles, such as domain experts who help interpret data and ensure relevance to the project's field, project managers who oversee the machine learning project lifecycle, product managers who plan the development of ML applications and software, and software engineers who build those applications.",
            "In addition, several more narrowly ML-focused roles are essential for an ML team:",
            "Once the ML team is formed, it's important that everything runs smoothly. Ensure that team members can easily share knowledge and resources to establish consistent workflows and best practices. For example, implement tools for collaboration, version control and project management, such as Git and Jira.",
            "Clear and thorough documentation is also important for debugging, knowledge transfer and maintainability. For ML projects, this includes documenting data sets, model runs and code, with detailed descriptions of data sources, preprocessing steps, model architectures, hyperparameters and experiment results.",
            "A common methodology for managing ML projects is MLOps, short for machine learning operations: a set of practices for deploying, monitoring and maintaining ML models in production. It draws inspiration from DevOps but accounts for the nuances that differentiate ML from software engineering. Just as DevOps improves collaboration between software developers and IT operations, MLOps connects data scientists and ML engineers with development and operations teams.",
            "By adopting MLOps, organizations aim to improve consistency, reproducibility and collaboration in ML workflows. This involves tracking experiments, managing model versions and keeping detailed logs of data and model changes. Keeping records of model versions, data sources and parameter settings ensures that ML project teams can easily track changes and understand how different variables affect model performance.",
            "Similarly, standardized workflows and automation of repetitive tasks reduce the time and effort involved in moving models from development to production. This includes automating model training, testing and deployment. After deploying, continuous monitoring and logging ensure that models are always updated with the latest data and performing optimally.",
            "The global AI market's value is expected to reach nearly $2 trillion by 2030, and the need for skilled AI professionals is growing in kind. Check out the following articles related to ML and AI professional development:",
            "ML development relies on a range of platforms, software frameworks, code libraries and programming languages. Here's an overview of each category and some of the top tools in that category.",
            "ML platforms are integrated environments that provide tools and infrastructure to support the ML model lifecycle. Key functionalities include data management; model development, training, validation and deployment; and postdeployment monitoring and management. Many platforms also include features for improving collaboration, compliance and security, as well as automated machine learning (AutoML) components that automate tasks such as model selection and parameterization.",
            "Each of the three major cloud providers offers an ML platform designed to integrate with its cloud ecosystem: Google Vertex AI, Amazon SageMaker and Microsoft Azure ML. These unified environments offer tools for model development, training and deployment, including AutoML and MLOps capabilities and support for popular frameworks such as TensorFlow and PyTorch. The choice often comes down to which platform integrates best with an organization's existing IT environment.",
            "In addition to the cloud providers' offerings, there are several third-party and open source alternatives. The following are some other popular ML platforms:",
            "ML frameworks and libraries provide the building blocks for model development: collections of functions and algorithms that ML engineers can use to design, train and deploy ML models more quickly and efficiently.",
            "In the real world, the terms framework and library are often used somewhat interchangeably. But strictly speaking, a framework is a comprehensive environment with high-level tools and resources for building and managing ML applications, whereas a library is a collection of reusable code for particular ML tasks.",
            "The following are some of the most common ML frameworks and libraries:",
            "In theory, almost any programming language can be used for ML. But in practice, most programmers choose a language for an ML project based on considerations such as the availability of ML-focused code libraries, community support and versatility.",
            "Much of the time, this means Python, the most widely used language in machine learning. Python is simple and readable, making it easy for coding newcomers or developers familiar with other languages to pick up. Python also boasts a wide range of data science and ML libraries and frameworks, including TensorFlow, PyTorch, Keras, scikit-learn, pandas and NumPy.",
            "Other languages used in ML include the following:",
            "Fueled by extensive research from companies, universities and governments around the globe, machine learning continues to evolve rapidly. Breakthroughs in AI and ML occur frequently, rendering accepted practices obsolete almost as soon as they're established. One certainty about the future of machine learning is its continued central role in the 21st century, transforming how work is done and the way we live.",
            "Several emerging trends are shaping the future of ML:",
            "Amid the enthusiasm, companies face challenges akin to those presented by previous cutting-edge, fast-evolving technologies. These challenges include adapting legacy infrastructure to accommodate ML systems, mitigating bias and other damaging outcomes, and optimizing the use of machine learning to generate profits while minimizing costs. Ethical considerations, data privacy and regulatory compliance are also critical issues that organizations must address as they integrate advanced AI and ML technologies into their operations.",
            "Lev Craig covers AI and machine learning as the site editor for TechTarget Editorial's Enterprise AI site. Craig graduated from Harvard University with a bachelor's degree in English and has previously written about enterprise IT, software development and cybersecurity.",
            "Linda Tucci is an executive industry editor at TechTarget Editorial. A technology writer for 20 years, she focuses on the CIO role, business transformation and AI technologies.",
            "Ed Burns, former executive editor at TechTarget, also contributed to this article.",
            "To help you find the right BI software for your analytics needs, here's a look at 20 top tools and the key features that ...",
            "Data preparation is a crucial but complex part of analytics applications. Don't let seven common challenges send your data prep ...",
            "A year after getting acquired by private equity firms amid declining revenue growth and a slow transition to the cloud, the ...",
            "President-elect Donald Trump has been vocal in his criticisms of big tech's content censorship power and President Joe Biden's ...",
            "Internal tech procurement can be a risky undertaking. Tech pilot programs can potentially reduce some of that risk, but IT ...",
            "Apart from President-elect Donald Trump's promise to take a strong stance on goods imported from China, collaboration might be ...",
            "Based on its AI development and expansion within data management, the record $10 billion the vendor raised shows it is viewed ...",
            "The data lakehouse pioneer has expanded into AI development and plans to use the funding to fuel further investments in AI, make ...",
            "The complementary partnership combines the data integration vendor's discovery and retrieval capabilities with the tech giant's ...",
            "The supply chain might be losing its seat at the executive table, but the work must continue to provide more resilience and ...",
            "Nothing is certain except death, taxes and supply chain disruptions. Companies should plan accordingly, especially as the ...",
            "Essential TMS features are real-time tracking, route optimization, carrier management, load planning, fleet management, automated...",
            "All Rights Reserved, \nCopyright 2018 - 2024, TechTarget\n\n\nPrivacy Policy\n\n\n\nCookie Preferences \n\n\n\nCookie Preferences \n\n\n\nDo Not Sell or Share My Personal Information"
        ]
    },
    {
        "url": "https://www.sas.com/en_us/insights/analytics/machine-learning.html",
        "title": "Machine Learning: What it is and why it matters | SAS",
        "content": [
            "Skip to main content",
            "Software Success",
            "Discover free resources and tailored guides to help you optimize your software experience.",
            "Learn to use your software",
            "Why SAS?",
            "Learn why SAS is the world's most trusted analytics platform, and why analysts, customers and industry experts love SAS.",
            "Learn more about SAS",
            "Select Your Region",
            "Americas",
            "Europe",
            "Middle East & Africa",
            "Asia Pacific",
            "Americas",
            "Europe",
            "Middle East & Africa",
            "Asia Pacific",
            "Hi !",
            "Create Profile",
            "My SAS",
            "Get access to My SAS, trials, communities and more.",
            "Edit Profile",
            "My SAS",
            "Get access to My SAS, trials, communities and more.",
            "SAS Sites",
            "Documentation",
            "Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence (AI) & based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.",
            "Because of new computing technologies, machine learning today is not like machine learning of the past. It was born from pattern recognition and the theory that computers can learn without being programmed to perform specific tasks; researchers interested in artificial intelligence wanted to see if computers could learn from data. The iterative aspect of machine learning is important because as models are exposed to new data, they can independently adapt. They learn from previous computations to produce reliable, repeatable decisions and results. It’s a science that’s not new – but one that has gained fresh momentum.",
            "Many machine learning algorithms have been around for a long time, and the ability to automatically apply complex mathematical calculations to big data – over and over, faster and faster – is ongoing. Here are a few widely publicized examples of machine learning applications you may be familiar with:",
            "While artificial intelligence (AI) is the broad science of mimicking human abilities, machine learning is a specific subset of AI that trains a machine how to learn. Watch this video to better understand the relationship between AI and machine learning. You'll see how these two technologies work, with useful examples and a few funny asides.",
            "By using algorithms to build models that uncover connections, organizations can make better decisions without human intervention. Learn more about the technologies that are shaping the world we live in.",
            "There are four types of machine learning algorithms: supervised, semisupervised, unsupervised and reinforcement. Learn about each type of algorithm and how it works. Then you'll be prepared to choose which one is best for addressing your business needs.",
            "A self-service, on-demand compute environment for data analysis and ML models increases productivity and performance while minimizing IT support and cost. In this Q&A, an expert explains why a developer workbench is an ideal environment for developers and modelers.",
            "Fast Company, the American Business Awards, PRNews and others have recognized SAS for innovative technology and social innovation projects. See why SAS is a leader in the 2024 Gartner® Magic Quadrant™ for Data Science and Machine Learning.",
            "Consumers have more trust in organizations that demonstrate responsible and ethical use of AI, like machine learning and generative AI. Learn why it’s essential to embrace AI systems designed for human centricity, inclusivity and accountability.",
            "CNG Holdings uses machine learning to enhance fraud detection and prevention while ensuring a smooth customer experience. By focusing on identity verification from the outset, they transitioned from reactive to proactive fraud prevention. Machine learning models help quickly validate identities, significantly reducing fraud instances and false positives. Real-time data access allows CNG to adjust strategies swiftly during fraud attempts, leading to reduced costs and more efficient investigations.",
            "Resurging interest in machine learning is due to the same factors that have made data mining and Bayesian analysis more popular than ever. Things like growing volumes and varieties of available data, computational processing that is cheaper and more powerful, affordable data storage.",
            "All of these things mean it's possible to quickly and automatically produce models that can analyze bigger, more complex data and deliver faster, more accurate results – even on a very large scale. And by building precise models, an organization has a better chance of identifying profitable opportunities – or avoiding unknown risks.",
            "What's required to create good machine learning systems?",
            "Did you know?",
            "Most industries working with large amounts of data have recognized the value of machine learning technology. By gleaning insights from this data – often in real time – organizations are able to work more efficiently or gain an advantage over competitors.",
            "Banks and others in the financial industry can use machine learning to improve accuracy and efficiency, identify important insights in data, detect and prevent fraud, and assist with anti-money laundering. Data mining, a subset of ML, can identify clients with high-risk profiles and incorporate cyber surveillance to pinpoint warning signs of fraud.",
            "Machine learning is a fast-growing trend in the health care industry, thanks to the advent of wearable devices and sensors that can use data to assess a patient's health in real time. The technology can also help medical experts analyze data to identify trends or red flags that may lead to improved diagnoses and treatment.",
            "Machine learning is revolutionizing the insurance industry by enhancing risk assessment, underwriting decisions and fraud detection. It also helps improve customer experience and boost profitability. By analyzing vast amounts of data, ML algorithms can evaluate risks more accurately, so insurers can tailor policies and pricing to customers.",
            "Machine learning and other AI and analytics techniques help accelerate research, improve diagnostics and personalize treatments for the life sciences industry. For example, researchers can analyze complex biological data, identify patterns and predict outcomes to speed drug discovery and development. For treatment, analyzing patient data allows therapies to be tailored to individual genetic profiles and health histories (for personalized medicine).",
            "Government agencies responsible for public safety and social services have a particular need for machine learning because they have multiple sources of data that can be mined for insights. Analyzing sensor data, for example, identifies ways to increase efficiency and save money. Machine learning can also help detect fraud and minimize identity theft.",
            "Websites that recommend items you might like based on previous purchases use machine learning to analyze your buying history. Retailers rely on machine learning to capture data, analyze it and use it to personalize a shopping experience, implement a marketing campaign, optimize prices, plan merchandise and gain customer insights.",
            "To get the most value from machine learning, you have to know how to pair the best algorithms with the right tools and processes. SAS combines rich, sophisticated heritage in statistics and data mining with new architectural advances to ensure your models run as fast as possible – in huge enterprise environments or in a cloud computing environment.",
            "Algorithms: SAS® graphical user interfaces help you build machine learning models and implement an iterative machine learning process. You don't have to be an advanced statistician. Our comprehensive selection of machine learning algorithms are included in many SAS products and can help you quickly get value from your big data – including data from the Internet of Things.",
            "SAS machine learning algorithms include:",
            "Expand list",
            "Tools and processes: As we know by now, it’s not just the algorithms. Ultimately, the secret to getting the most value from your big data lies in pairing the best algorithms for the task at hand with:",
            "Get in-depth instruction and free access to SAS software to build your machine learning skills. Courses include: 14 hours of course time, 90 days of free software access in the cloud and a flexible e-learning format, with no programming skills required.",
            "Two of the most widely adopted machine learning methods are supervised learning and unsupervised learning – but there are also other methods of machine learning. Here's an overview of the most popular types.",
            "Supervised learning",
            "Supervised learning algorithms are trained using labeled examples, such as an input where the desired output is known. For example, a piece of equipment could have data points labeled either “F” (failed) or “R” (runs). The learning algorithm receives a set of inputs along with the corresponding correct outputs, and the algorithm learns by comparing its actual output with correct outputs to find errors. It then modifies the model accordingly. Through methods like classification, regression, prediction and gradient boosting, supervised learning uses patterns to predict the values of the label on additional unlabeled data. Supervised learning is commonly used in applications where historical data predicts likely future events. For example, it can anticipate when credit card transactions are likely to be fraudulent or which insurance customer is likely to file a claim.",
            "Unsupervised learning",
            "Unsupervised learning is used against data that has no historical labels. The system is not told the \"right answer.\" The algorithm must figure out what is being shown. The goal is to explore the data and find some structure within. Unsupervised learning works well on transactional data. For example, it can identify segments of customers with similar attributes who can then be treated similarly in marketing campaigns. Or it can find the main attributes that separate customer segments from each other. Popular techniques include self-organizing maps, nearest-neighbor mapping, k-means clustering and singular value decomposition. These algorithms are also used to segment text topics, recommend items and identify data outliers.",
            "Semisupervised learning",
            "Semisupervised learning is used for the same applications as supervised learning. But it uses both labeled and unlabeled data for training – typically a small amount of labeled data with a large amount of unlabeled data (because unlabeled data is less expensive and takes less effort to acquire). This type of learning can be used with methods such as classification, regression and prediction. Semisupervised learning is useful when the cost associated with labeling is too high to allow for a fully labeled training process. Early examples of this include identifying a person's face on a webcam.",
            "Reinforcement learning",
            "Reinforcement learning is often used for robotics, gaming and navigation. It's also used in conjunction with generative AI techniques, like large language models. With reinforcement learning, the algorithm discovers through trial and error which actions yield the greatest rewards. This type of learning has three primary components: the agent (the learner or decision maker), the environment (everything the agent interacts with) and actions (what the agent can do). The objective is for the agent to choose actions that maximize the expected reward over a given amount of time. The agent will reach the goal much faster by following a good policy. So the goal in reinforcement learning is to learn the best policy.",
            "Although all of these methods have the same goal – to extract insights, patterns and relationships that can be used to make decisions – they have different approaches and abilities.",
            "Data mining can be considered a superset of many different methods to extract insights from data. It might involve traditional statistical methods and machine learning. Data mining applies methods from many different areas to identify previously unknown patterns from data. This can include statistical algorithms, machine learning, text analytics, time series analysis and other areas of analytics. Data mining also includes the study and practice of data storage and data manipulation.",
            "Similar to statistical models, the goal of machine learning is to understand the structure of the data – to fit well-understood theoretical distributions to the data. With statistical models, there is a theory behind the model that is mathematically proven, but this requires that data meets certain strong assumptions. Machine learning has developed based on the ability to use computers to probe the data for structure, even if we don't have a theory of what that structure looks like. The test for a machine learning model is a validation error on new data, not a theoretical test that proves a null hypothesis. Because machine learning often uses an iterative approach to learn from data, the learning can be easily automated. Passes are run through the data until a robust pattern is found.",
            "Deep learning combines advances in computing power and special types of neural networks to learn complicated patterns in large amounts of data. Deep learning techniques are currently state of the art for identifying objects in images and words in sounds. Researchers are now looking to apply these successes in pattern recognition to more complex tasks such as automatic language translation, medical diagnoses and numerous other important social and business problems.",
            "Purpose-built for developers and modelers, SAS® Viya® Workbench is a self-service, on-demand compute environment for analytical development, including building AI and machine learning models for better data analysis.",
            "SAS data and AI solutions provide our global customers with knowledge they can trust in the moments that matter, inspiring bold new innovations across industries.",
            "Explore",
            "What is...",
            "Share this\nShare this page with friends or colleagues."
        ]
    },
    {
        "url": "https://www.technologyreview.com/2018/11/17/103781/what-is-machine-learning-we-drew-you-another-flowchart/",
        "title": "What is machine learning? | MIT Technology Review",
        "content": [
            "Machine-learning algorithms find and apply patterns in data. And they pretty much run the world.",
            "Machine-learning algorithms are responsible for the vast majority of the artificial intelligence advancements and applications you hear about. (For more background, check out our first flowchart on \"What is AI?\" here.)",
            "Machine-learning algorithms use statistics to find patterns in massive* amounts of data. And data, here, encompasses a lot of things—numbers, words, images, clicks, what have you. If it can be digitally stored, it can be fed into a machine-learning algorithm.",
            "Machine learning is the process that powers many of the services we use today—recommendation systems like those on Netflix, YouTube, and Spotify; search engines like Google and Baidu; social-media feeds like Facebook and Twitter; voice assistants like Siri and Alexa. The list goes on.",
            "In all of these instances, each platform is collecting as much data about you as possible—what genres you like watching, what links you are clicking, which statuses you are reacting to—and using machine learning to make a highly educated guess about what you might want next. Or, in the case of a voice assistant, about which words match best with the funny sounds coming out of your mouth.",
            "Frankly, this process is quite basic: find the pattern, apply the pattern. But it pretty much runs the world. That’s in big part thanks to an invention in 1986, courtesy of Geoffrey Hinton, today known as the father of deep learning.",
            "Deep learning is machine learning on steroids: it uses a technique that gives machines an enhanced ability to find—and amplify—even the smallest patterns. This technique is called a deep neural network—deep because it has many, many layers of simple computational nodes that work together to munch through data and deliver a final result in the form of the prediction.",
            "Neural networks were vaguely inspired by the inner workings of the human brain. The nodes are sort of like neurons, and the network is sort of like the brain itself. (For the researchers among you who are cringing at this comparison: Stop pooh-poohing the analogy. It’s a good analogy.) But Hinton published his breakthrough paper at a time when neural nets had fallen out of fashion. No one really knew how to train them, so they weren’t producing good results. It took nearly 30 years for the technique to make a comeback. And boy, did it make a comeback.",
            "One last thing you need to know: machine (and deep) learning comes in three flavors: supervised, unsupervised, and reinforcement. In supervised learning, the most prevalent, the data is labeled to tell the machine exactly what patterns it should look for. Think of it as something like a sniffer dog that will hunt down targets once it knows the scent it’s after. That’s what you’re doing when you press play on a Netflix show—you’re telling the algorithm to find similar shows.",
            "In unsupervised learning, the data has no labels. The machine just looks for whatever patterns it can find. This is like letting a dog smell tons of different objects and sorting them into groups with similar smells. Unsupervised techniques aren’t as popular because they have less obvious applications. Interestingly, they have gained traction in cybersecurity.",
            "Lastly, we have reinforcement learning, the latest frontier of machine learning. A reinforcement algorithm learns by trial and error to achieve a clear objective. It tries out lots of different things and is rewarded or penalized depending on whether its behaviors help or hinder it from reaching its objective. This is like giving and withholding treats when teaching a dog a new trick. Reinforcement learning is the basis of Google’s AlphaGo, the program that famously beat the best human players in the complex game of Go.",
            "That’s it. That's machine learning. Now check out the flowchart above for a final recap.",
            "*Note: Okay, there are technically ways to perform machine learning on smallish amounts of data, but you typically need huge piles of it to achieve good results.",
            "___",
            "This originally appeared in our AI newsletter The Algorithm. To have it directly delivered to your inbox, subscribe here for free.",
            "A two-hour interview is enough to accurately capture your values and preferences, according to new research from Stanford and Google DeepMind.",
            "The game was created from clips and keyboard inputs alone, as a demo for real-time interactive video generation.",
            "Rapid advances in applying artificial intelligence to simulations in physics and chemistry have some people questioning whether we will even need quantum computers at all.",
            "Everything you need to know about the state of AI.",
            "Discover special offers, top stories,\n            upcoming events, and more.",
            "Thank you for submitting your email!",
            "It looks like something went wrong.",
            "We’re having trouble saving your preferences.\n                Try refreshing this page and updating them one\n                more time. If you continue to get this message,\n                reach out to us at\n                customer-service@technologyreview.com with a list of newsletters you’d like to receive.",
            "© 2024 MIT Technology Review"
        ]
    },
    {
        "url": "https://cloud.google.com/learn/artificial-intelligence-vs-machine-learning",
        "title": "AI vs. Machine Learning: How Do They Differ? | Google Cloud",
        "content": [
            "You might hear people use artificial intelligence (AI) and machine learning (ML) interchangeably, especially when discussing big data, predictive analytics, and other digital transformation topics. The confusion is understandable as artificial intelligence and machine learning are closely related. However, these trending technologies differ in several ways, including scope, applications, and more.",
            "Increasingly AI and ML products have proliferated as businesses use them to process and analyze immense volumes of data, drive better decision-making, generate recommendations and insights in real time, and create accurate forecasts and predictions.",
            "So, what exactly is the difference when it comes to ML vs. AI, how are ML and AI connected, and what do these terms mean in practice for organizations today?",
            "We’ll break down AI vs. ML and explore how these two innovative concepts are related and what makes them different from each other.",
            "New customers get up to $300 in free credits to try Vertex AI and other Google Cloud products.",
            "Artificial intelligence is a broad field, which refers to the use of technologies to build machines and computers that have the ability to mimic cognitive functions associated with human intelligence, such as being able to see, understand, and respond to spoken or written language, analyze data, make recommendations, and more.",
            "Although artificial intelligence is often thought of as a system in itself, it is a set of technologies implemented in a system to enable it to reason, learn, and act to solve a complex problem.",
            "Machine learning is a subset of artificial intelligence that automatically enables a machine or system to learn and improve from experience. Instead of explicit programming, machine learning uses algorithms to analyze large amounts of data, learn from the insights, and then make informed decisions.",
            "Machine learning algorithms improve performance over time as they are trained—exposed to more data. Machine learning models are the output, or what the program learns from running an algorithm on training data. The more data used, the better the model will get.",
            "While AI and ML are not quite the same thing, they are closely connected. The simplest way to understand how AI and ML relate to each other is:",
            "One helpful way to remember the difference between machine learning and artificial intelligence is to imagine them as umbrella categories. Artificial intelligence is the overarching term that covers a wide variety of specific approaches and algorithms. Machine learning sits under that umbrella, but so do other major subfields, such as deep learning, robotics, expert systems, and natural language processing.",
            "While artificial intelligence encompasses the idea of a machine that can mimic human intelligence, machine learning does not. Machine learning aims to teach a machine how to perform a specific task and provide accurate results by identifying patterns.",
            "Let’s say you ask your Google Nest device, “How long is my commute today?” In this case, you ask a machine a question and receive an answer about the estimated time it will take you to drive to your office. Here, the overall goal is for the device to perform a task successfully—a task that you would generally have to do yourself in a real-world environment (for example, research your commute time).",
            "In the context of this example, the goal of using ML in the overall system is not to enable it to perform a task. For instance, you might train algorithms to analyze live transit and traffic data to forecast the volume and density of traffic flow. However, the scope is limited to identifying patterns, how accurate the prediction was, and learning from the data to maximize performance for that specific task.",
            "AI and ML bring powerful benefits to organizations of all shapes and sizes, with new possibilities constantly emerging. In particular, as the amount of data grows in size and complexity, automated and intelligent systems are becoming vital to helping companies automate tasks, unlock value, and generate actionable insights to achieve better outcomes.",
            "Here are some of the business benefits of using artificial intelligence and machine learning:",
            "Wider data ranges",
            "Analyzing and activating a wider range of unstructured and structured data sources.",
            "Faster decision-making",
            "Improving data integrity, accelerating data processing, and reducing human error for more informed, faster decision-making.",
            "Efficiency",
            "Increasing operational efficiency and reducing costs.",
            "Analytic integration",
            "Empowering employees by integrating predictive analytics and insights into business reporting and applications.",
            "Companies across industries are using AI and ML in various ways to transform how they work and do business. Incorporating AI and ML capabilities into their strategies and systems helps organizations rethink how they use their data and available resources, drive productivity and efficiency, enhance data-driven decision-making through predictive analytics, and improve customer and employee experiences.",
            "Here are some of the most common applications of AI and ML:",
            "Patient health record analysis and insights, outcome forecasting and modeling, accelerated drug development, augmented diagnostics, patient monitoring, and information extraction from clinical notes.",
            "Production machine monitoring, predictive maintenance, IoT analytics, and operational efficiency.",
            "Inventory and supply chain optimization, demand forecasting, visual search, personalized offers and experiences, and recommendation engines.",
            "Risk assessment and analysis, fraud detection, automated trading, and service processing optimization.",
            "Intelligent networks and network optimization, predictive maintenance, business process automation, upgrade planning, and capacity forecasting.",
            "Google Cloud offers a wide range of AI and ML tools to help your teams focus on the valuable work that matters most. Designed and built with the best of Google’s research and technology, our products and services are helping organizations transform and solve their most challenging real-world problems.",
            "Start building on Google Cloud with $300 in free credits and 20+ always free products."
        ]
    }
]